---
title: 'Data work in the "tidyverse"'
author:
  name: Grant R. McDermott
  affiliation: University of Oregon | EC 607
  # email: grantmcd@uoregon.edu
date: Lecture 5 #"`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    theme: flatly
    highlight: haddock 
    # code_folding: show
    toc: yes
    toc_depth: 4
    toc_float: yes
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
```

## Requirements

### R packages 

- **New:** `nycflights13`
- **Already used:** `tidyverse`

```{r, eval=FALSE}
install.packages("nycflights13")
```

## Tidyverse basics

### Student presentation: Tidy data

If you're reading this after the fact, I recommend going through the original paper: "[Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf)" (Hadley Wickham, 2014 *JSS*). I also recommend this [vignette](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) from the `tidyr` package, although we'll cover much of the same ground today. The summary version is that tidy data are characterised by three features:

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

We've revisit these features later in the lecture, but it should immediately be apparent to you that tidy data is more likely to be [long (i.e. narrow) format](https://en.wikipedia.org/wiki/Wide_and_narrow_data) than wide format. We'll also see that there are some tradeoffs for data that is optimised for human reading vs data that is optimised for machine reading. 

### Tidyverse vs. base R

Much digital ink has been spilled over the "tidyverse vs. base R" debate. I won't delve into this debate here, because I think the answer is [obvious](http://varianceexplained.org/r/teach-tidyverse/): We should teach (and learn) the tidyverse first.

- The documentation and community support are outstanding.
- Having a consistent philosophy and syntax makes it much easier to learn.
- For data cleaning, wrangling and plotting... the tidyverse is really a no-brainer.^[I should say that I'm also a fan of the [data.table](https://github.com/Rdatatable/data.table/wiki) package for data work. I may come back to this package once we reach the big data section of the course.]

But this certainly shouldn't put you off learning base R alternatives.

- Base R is extremely flexible and powerful (esp. when combined with other libraries).
- There are some things that you'll have to venture outside of the tidyverse for.
- A combination of tidyverse and base R is often the best solution to a problem.

One point of convenience is that there is often a direct correspondence between a tidyverse command and its base R equivalent. These invariably follow a `tidyverse::snake_case` vs `base::period.case` rule. E.g. see:
- `?readr::read_csv` vs `?utils::read.csv`
- `?tibble::data_frame`vs `?base::data.frame`
- `?dplyr::if_else` vs `?base::ifelse`
- etc.
  
If you call up the above examples, you'll see that the tidyverse alternative typically offers some enhancements or other useful options (and sometimes restrictions) over its base counterpart. Remember: There are always many ways to achieve a single goal in R.

### Tidyverse packages

Let's load the tidyverse meta-package and check the output.
```{r tverse}
library(tidyverse)
```

We see that we have actually loaded a number of packages (which could also be loaded individually): `ggplot2`, `tibble`, `dplyr`, etc. We can also see information about the package versions and some namespace conflicts --- remember those from last week?

The tidyverse actually comes with a lot more packages than those that are just loaded automatically.^[It also includes a lot of dependencies upon installation.] You can see the full list by typing:
```{r tverse_pkgs}
tidyverse_packages()
```

We'll use several of these additional packages during the remainder of this course. For example, the `lubridate` package for working with dates and the `rvest` package for webscraping. However, I want you to bear in mind that these packages will have to be loaded separately.

### Today's focus: `dplyr` and `tidyr`

I hope to cover most of the tidyverse packages over the length of this course. Today, however, I'm only really going to focus on two packages: 

1. `dplyr`
2. `tidyr`

These are the workhorse packages for cleaning and wrangling data. They are thus the ones that you will likely make the most use of (alongside `ggplot2`, which we already met back in Lecture 1). Data cleaning and wrangling occupies an inordinate amount of time, no matter where you are in your research career.

### An aside on the pipe: `%>%`

We already learned about pipes in our lecture on the bash shell.^[Where they were denoted `|`.] In R, the pipe operator is denoted `%>%` and is automatically loaded with the tidyverse. I want to reiterate how cool pipes are, and how using them can dramatically improve the experience of reading and writing code. To do so, let's compare two lines of code that do identical things: Get the mean fuel efficiency of a particular set of vehicles.

This first line of code reads from left to right, exactly how I thought of the operations in my head: Take this object (the [mpg](https://ggplot2.tidyverse.org/reference/mpg.html) dataset), then do this (filter down to Audi vehicles), then do this (group by model type), and finally do this (get the mean highway miles per gallon for each group class).

```{r pipe}
## Piped version
mpg %>% filter(manufacturer=="audi") %>% group_by(model) %>% summarise(hwy_mean = mean(hwy))
```

Now contrast it with this second line of code, which totally inverts the logical order of my thought process. (The final operation comes first!) Who wants to read things inside out?

```{r nonpipe}
## Non-piped
summarise(group_by(filter(mpg, manufacturer=="audi"), model), hwy_mean = mean(hwy))
```

The piped version of the code is even more readable if we write it over several lines. (Remember: Using vertical space costs nothing and makes for much more readable/writeable code than cramming things horizontally.) Here it is again, although I won't evaluate the code this time.

```{r pipe2, eval=F}
mpg %>% 
  filter(manufacturer=="audi") %>% 
  group_by(model) %>% 
  summarise(hwy_mean = mean(hwy))
```

PS â€” The pipe is originally from the [magrittr](https://magrittr.tidyverse.org/) package ([geddit?](https://en.wikipedia.org/wiki/The_Treachery_of_Images)), which can do some other cool things if you're inclined to explore.

## Data wrangling with `dplyr`

There are five key `dplyr` verbs that you need to learn.

1. `filter()`: Filter (i.e. subset) rows based on their values.

2. `arrange()`: Arrange (i.e. reorder) rows based on their values.

3. `select()`: Select (i.e. subset) columns by their names: 

4. `mutate()`: Create new columns.

5. `summarise()`: Collapse multiple rows into a single summary value.^[`summarize()` with a "z" works too. R doesn't discriminate against uncivilised nations of the world.]

Let's practice these commands together using the starwars data frame that comes pre-packaged with `dplyr`.

### 1) `dplyr::filter()`

We use `filter()` to subset data based on rows values. For example, let's say we only want to look at tall humans in the Star Wars catalogue:

```{r filter0}
starwars %>% 
  filter(species == "Human") %>%
  filter(height >= 190) 
```

Note that we can chain multiple filter commands with the pipe (`%>%`), or simply separate them within a single filter command using commas.

```{r filter1}
starwars %>% 
  filter( 
    species == "Human", 
    height >= 190
    ) 
```

Regular expressions work well too.
```{r filter2}
starwars %>% 
  filter(grepl("Skywalker", name))
```

A very common `filter()` use case is identifying (or removing) missing data cases. 
```{r filter3}
starwars %>% 
  filter(is.na(height))
```

To remove missing observations, simply use negation: `filter(!is.na(height))`. Try this yourself now.

### 2) `dplyr::arrange()`

We use `arrange()` when we want to (re)order data based on row values. For example, say we want to sort the characters from youngest to oldest.

```{r arrange1}
starwars %>% 
  arrange(birth_year)
```

(Note that arranging on a character-based column --- i.e. strings --- will sort the data alphabetically. Try this yourself by arranging according to the "name" column.)

We can also arrange items in descending order using `arrange(desc())`.
```{r arrange2}
starwars %>% 
  arrange(desc(birth_year))
```

### 3) `dplyr::select()`

So far we have been focusong on row-based operations. However, we use `select()` to subset data based on the columns. To select multiple columns, you can use commas. (Or, if you are selecting consecutive columns, you can also use the "first_column:last_column" format). 
```{r select0}
starwars %>% 
  select(name:skin_color, species)
```

You can deselect a column with a minus sign (i.e. "-"). Note, however, that deselecting multiple columns would require wrapping them in concatenation parenthesese: `select(..., -c(col1, col2, etc))`.

```{r select1}
starwars %>% 
  select(name:skin_color, species, -height)
```

You can also rename some (or all) of your selected variables in place.^[A related command is "rename", which is useful if you just want to rename columns without changing the selection. See `?rename`.]  
```{r select2}
starwars %>%
  select(alias=name, crib=homeworld, sex=gender) 
```

The `select(contains(PATTERN))` option provides a nice shortcut in relevant cases.
```{r select3}
starwars %>% 
  select(name, contains("color"))
```

The `select(..., everything())` option is another useful shortcut if you want to bring some variable(s) to the "front" of your dataset.

```{r select4}
starwars %>% 
  select(species, homeworld, everything())
```


### `4) dplyr::mutate()`

We use `mutate()` to create new columns (i.e. variables). You can either create new columns from scratch, or (more commonly) as transformations of existing columns.
```{r mutate1}
starwars %>% 
  select(name, birth_year) %>%
  mutate(dog_years = birth_year * 7) %>%
  mutate(comment = paste0(name, " is ", dog_years, " in dog years."))
```

Note that `mutate()` is order aware. So you can chain multiple mutations in a single call, even if a a latter mutation relies on an earlier one.
```{r mutate2}
starwars %>% 
  select(name, birth_year) %>%
  mutate(
    dog_years = birth_year * 7, ## Separate with a comma
    comment = paste0(name, " is ", dog_years, " in dog years.")
    )
```

Boolean, logical and conditional operators all work well with `mutate()` too.
```{r mutate3}
starwars %>% 
  select(name, height) %>%
  filter(name %in% c("Luke Skywalker", "Anakin Skywalker")) %>% 
  mutate(tall1 = height > 180) %>%
  mutate(tall2 = ifelse(height > 180, "Tall", "Short")) ## Same effect, but can choose labels

```

Lastly, there are "scoped" variants of `mutate()` that work on a subset of variables.
- `mutate_all()` affects every variable
- `mutate_at()` affects named or selected variables
- `mutate_if()` affects variables that meet some criteria (e.g. are numeric)

See `?mutate_all` for more details and examples, but here's a silly example using the latter:

```{r, mutate4}
starwars %>% select(name:eye_color) %>% mutate_if(is.character, toupper)
```


### `5) dplyr::summarise()`

We use `summarise()` (or `summarize()`) when we want collapse multiple observations (i.e. rows) down into a single observation. This is particularly useful in combination with the `group_by()` command.
```{r summ1}
starwars %>% 
  group_by(species, gender) %>% 
  summarise(mean_height = mean(height, na.rm = T))
```

Note that including "na.rm=T" is usually a good idea with summary functions. Otherwise, any missing value will propogate to the summarised value too.
```{r summ2}
## Probably not what we want
starwars %>% summarise(mean_height = mean(height))
## Much better
starwars %>% summarise(mean_height = mean(height, na.rm=T))
```

The "scoped" variants that we saw earlier also work with `summarise()`
- `summarise_all()` affects every variable
- `summarise_at()` affects named or selected variables
- `summarise_if()` affects variables that meet some criteria (e.g. are numeric)

Again, see `?summarise_at` for more details and examples. However, here's an example using the latter:

```{r, summ4}
starwars %>% group_by(species, gender) %>% summarise_if(is.numeric, mean, na.rm=T)
```

And one more, just to show how we can add flexibility to our scoped calls. This time, I going to use the `funs(suffix=FUNCTION)` option, which will append a helpful suffix to our summarised variables. (You can also use it to implement scoped transformations based on your own functions.)

```{r, summ5}
starwars %>% group_by(species, gender) %>% summarise_if(is.numeric, funs(avg=mean), na.rm=T)
```

### Other dplyr goodies

`group_by()` and `ungroup()`: For (un)grouping.

- Particularly useful with the `summarise()` and `mutate()` commands, as we've already seen.

`slice()`: Subset rows by position rather than filtering by values.

- E.g. `starwars %>% slice(c(1, 5))`

`pull()`: Extract a column from as a data frame as a vector or scalar.

- E.g. `starwars %>% filter(gender=="female") %>% pull(height)`

`count()` and `distinct()`: Number and isolate unique observations.

- E.g. `starwars %>% count(species)`, or `starwars %>% distinct(species)`
- You could also use a combination of `mutate()`, `group_by()`, and `n()`, e.g. `starwars %>% group_by(species) %>% mutate(num = n())`.

There are also a whole class of [window functions](https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html) for getting leads and lags, ranking, creating cumulative aggregates, etc.

- See `vignette("window-functions")`.

The final set of dplyr "goodies" are the family of join operations. However, these are important enough that I want to go over some concepts in a bit more depth. (We encounter and practice these many more times as the course progresses.)

### Joining operations

One of the mainstays of the dplyr package is merging data with the family [join operations](https://cran.r-project.org/web/packages/dplyr/vignettes/two-table.html).

- `inner_join(df1, df2)`
- `left_join(df1, df2)`
- `right_join(df1, df2)`
- `full_join(df1, df2)`
- `semi_join(df1, df2)`
- `anti_join(df1, df2)`

For the simple examples that I'm going to show here, we'll need some data sets that come bundled with the [nycflights13 package](http://github.com/hadley/nycflights13). Let's load it now and quickly inspect the `flights` and `planes` datasets.

```{r flights}
library(nycflights13)
flights 
planes
```

Let's perform a [left join](https://stat545.com/bit001_dplyr-cheatsheet.html#left_joinsuperheroes-publishers) on the flights and planes datasets. I'm also going subset columns after the join using `select()`, but only to keep the columns readable on this page.

```{r join1}
# flights %>% left_join(planes) ## works too
left_join(flights, planes) %>%
  select(year, month, day, dep_time, arr_time, carrier, flight, tailnum, type, model)
```

Note that `dplyr` made a reasonable guess about which columns to join on (i.e. columns that share the same name). It also told us its choices: 

```
*## Joining, by = c("year", "tailnum")
```

However, there's an obvious problem here: the variable "year" does not have a consistent meaning across our joining datasets! (In one it refers to the *year of flight*, in the other it refers to *year of construction*.) 

Luckily, there's an easy way to avoid this problem: You just need to be more explicit in your join call by using the `by = ` argument. You can also rename any ambiguous columns to avoid confusion. 
```{r join2}
left_join(
  flights,
  planes %>% rename(year_built = year), ## Not necessary w/ below line, but helpful
  by = "tailnum" ## Be specific about the joining column
  ) %>%
  select(year, month, day, dep_time, arr_time, carrier, flight, tailnum, year_built, type, model)
```

I'll mention one last thing for now. Note what happens if we again specify the join column... but this time don't rename the ambiguous "year" column in at least one of the given data frames.
```{r join3}
left_join(
  flights,
  planes, ## Not renaming "year" to "year_built" this time
  by = "tailnum"
  ) %>%
  select(contains("year"), month, day, dep_time, arr_time, carrier, flight, tailnum, type, model)
```

Bottom line: Make sure you know what "year.x" and "year.y" are. Again, it pays to be specific.


## Data tidying with `tidyr`

Similar to `dplyr`, there are a set of key `tidyr` verbs that need to learn.

1. `gather()`: Gather (or "melt") wide data into long format

2. `spread()`: Spread (or "cast") long data into wide format. 

3. `separate()`: Separate (i.e. split) one column into multiple columns.

4. `unite()`: Unite (i.e. combine) multiple columns into one.

Let's practice these verbs together. (Side question: Which of `gather()` vs `spread()` produces "tidy" data?)

### 1) `tidyr::gather()`

For the next few examples, I'm going to create some new data frames.^[Actually, I'm going to use the tidyverse-enhanced version of data frames, i.e. "tibbles", but that's certaintly not necessary.] Remember that in R this easy (encouraged even!) because it allows for multiple objects in memory at the same time.

Let's start out with a data frame of hypothetical stock prices.

```{r gather0}
stocks <- 
  tibble( ## Could use a standard "data.frame" instead of "tibble" if you prefer
    time = as.Date('2009-01-01') + 0:1,
    X = rnorm(2, 0, 1),
    Y = rnorm(2, 0, 2),
    Z = rnorm(2, 0, 4)
    )
stocks
```

The data are in untidy ("wide") format. We'll use `gather()` to convert it to tidy ("narrow") format. 

```{r gather1}
tidy_stocks <- stocks %>% gather(stock, price, -time)
tidy_stocks
```

Notice that we used the minus sign (`-`) to exclude the "time" variable from the gathering process. In effect, we were telling `gather()` that this variable is already in tidy format and can act as an anchor point for the remaining transformation. (Try running the previous code chunk without excluding "time" from the `gather()` transformation. What happens?)


**Aside: Remembering the `gather()` syntax.** There's a long-running joke about no-one being able to remember Stata's "reshape" command. ([Exhibit A](https://twitter.com/scottimberman/status/1036801308785864704).) It's easy to see this happening with `gather()` too. However, I find that I never forget the command as long as I remember the argument order is *"key"* then *"value"*.
```{r gather2}
## Write out the argument names this time: i.e. "key=" and "value="
stocks %>% gather(key=stock, value=price, -time)
```

### 2) `tidyr::spread()`

`spread()` moves in the opposite direction, converting data from narrow format to wide format. While this would appear to contravene our adherence to tidy data principles, there are occasions where it makes sense. For example, if you want to to view a dataset in more human-readable form, or if you want to use a `ggplot2` geom that requires "ymin" and "ymax" aesthetics as separate variables (e.g. [geom_pointrange](https://ggplot2.tidyverse.org/reference/geom_linerange.html) or [geom_ribbon](https://ggplot2.tidyverse.org/reference/geom_ribbon.html).)

```{r spread1}
tidy_stocks %>% spread(stock, price)
```

Another use case is if you want to spread your data over a different wide format. This approach effectively combines `gather()` and `separate()`, with each step emphasising different key-value combinations. For example, maybe we want the data to be wide in tems of dates.

```{r spread2}
tidy_stocks %>% spread(time, price)
```

### 3) `tidyr::separate()`

We can use `separate()` to split one column into two, based on an identifiable separation character.

```{r sep1}
economists <- tibble(name = c("Adam.Smith", "Paul.Samuelson", "Milton.Friedman"))
economists
economists %>% separate(name, c("first_name", "last_name")) 
```

The `separate()` command is pretty smart. But to avoid ambiguity, you can also specify the separation character with `separate(..., sep=".")`. Try this yourself to confirm.

A related function is `separate_rows()`, for splitting up cells that contain multiple fields or observations (a frustratingly common occurence with survey data).
```{r sep2}
jobs <- 
  tibble(
    name = c("Jack", "Jill"),
    occupation = c("Homemaker", "Philosopher, Philanthropist, Troublemaker") 
    )
```

Now split out Jill's various occupations into different rows

```{r sep3}
jobs %>% separate_rows(occupation)
```

### 4) `tidyr::unite()`

In direct contrast to `separate()`, we can use `unite()` to combine multiple columns into one.

```{r unite1}
gdp <- 
  tibble(
    yr = rep(2016, times = 4),
    mnth = rep(1, times = 4),
    dy = 1:4,
    gdp = rnorm(4, mean = 100, sd = 2)
    )
gdp 
## Combine "yr", "mnth", and "dy" into one "date" column
gdp %>% unite(date, c("yr", "mnth", "dy"), sep = "-")
```

One thing I want to flag is that `unite()` will automatically create a character variable. If you want to convert it to something else (e.g. date or numeric) then you will need to modify it using `mutate()`.^[`transmute` is another option. It is a variation of `mutate()`, whichs drops existing variables.] Here's an example using one of the [lubridate](https://lubridate.tidyverse.org/) package's incredibly helpful date conversion functions.

```{r unite2, message=F}
library(lubridate)
gdp %>% 
  unite(date, c("yr", "mnth", "dy"), sep = "-") %>%
  mutate(date = ymd(date))
```

### Other tidyr goodies

Use `crossing()` to get the full combination of a group of variables.^[Base R alternative: `expand.grid()`]

```{r cross1}
crossing(side=c("left", "right"), height=c("top", "bottom"))
```

See `?expand()` and `?complete()` for more specialised functions that allow you to fill in (implicit) missing data or variable combinations in existing data frames.

- You'll encounter this during your next assignment.

## Summary

### Key verbs

A huge amount data wrangling and tidying can achieved simply by remembering some key tidyverse verbs.

For `dplyr`:

1. `filter()`
2. `arrange()`
3. `select()`
4. `mutate()`
5. `summarise()`

For `tidyr`:

1. `gather()`
2. `spread()`
3. `separate()`
4. `unite()`

Other useful items include: pipes (`%>%`), grouping (`group_by()`), joining functions (`left_join()`, `inner_join`, etc.).

### Assignment 2

Assignment 2 is now up on GitHub Classroom.

- Hone your data wrangling and cleaning skills on a dataset culled from the wild.
- This one will take some of you a while to get through, so please get started early.
- Deadline: One week from today.

### Next lecture 

The first of our webscraping lectures.
